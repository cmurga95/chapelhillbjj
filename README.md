# ğŸ“Š Automated Attendance Pipeline & Dashboard


### ğŸ“Œ Overview
This project automates the extraction, transformation, and reporting of member attendance data from a PushPress Looker dashboard.
It demonstrates how to build a full-stack data pipeline, leveraging automation, cloud database engineering, and interactive dashboards to generate actionable business insights.

### ğŸš€ Key Features
âœ… Automated scraping of an embedded dashboard (with secure login & filter selection)
âœ… Dynamic query manipulation (e.g., increase export limits)
âœ… Parsing and storing clean data in Supabase (PostgreSQL)
âœ… SQL views & triggers to transform and manage data
âœ… Interactive web app in Shiny for real-time monitoring
âœ… Additional Looker dashboard to track new leads & kidsâ€™ attendance trends

### ğŸ”— Full Workflow
```mermaid
flowchart LR
  A["***Automated Scraper***(Python + Playwright)"]
  B["***Supabase***(PostgreSQL)"]
  C["SQL Views & Triggers"]
  D["Shiny Web App"]
  E["Looker Dashboard"]

  A --> B
  B --> C
  C --> D
  C --> E
```
### How it works:
1ï¸âƒ£ Authenticate â†’ filter â†’ export fresh data automatically
2ï¸âƒ£ Clean and push data to Supabase
3ï¸âƒ£ Use views to filter kids vs. adults & identify new members
4ï¸âƒ£ Triggers keep summary tables updated
5ï¸âƒ£ Serve insights via Shiny and Looker dashboards

### ğŸ—„ï¸ Data Pipeline Highlights
Automation: Playwright handles login, filter selection, dynamic CSV exports, and URL manipulation.

Cloud Storage: Supabase Postgres stores all check-ins, sessions, and member details.

Data Modeling: SQL views separate kidsâ€™ attendance and identify new kids for promotions.

Business Logic: Triggers & functions automatically manage new lead records.

Reporting: Shiny dashboard for internal use, Looker for stakeholder reporting.

### ğŸ”’ Security & Best Practices
.env files used for API keys and credentials â€” never hardcoded.

### ğŸ› ï¸ Tech Stack
| Layer            | Tool/Framework            |
| ---------------- | ------------------------- |
| **Automation**   | Python, Playwright        |
| **Data Storage** | Supabase (PostgreSQL)     |
| **Processing**   | SQL (views, triggers)     |
| **Reporting**    | Shiny, Looker Studio      |
| **Deployment**   | GitHub Actions & Supabase |


### âœ¨ Impact
âœ… Improved data accuracy & consistency by automating manual CSV exports
âœ… Reduced admin effort for tracking kidsâ€™ promotions & new leads
âœ… Better business insights with self-serve dashboards & real-time updates

### ğŸ“‚ Repository Structure
```bash
â”œâ”€â”€ playwright/              # Scraper scripts
â”œâ”€â”€ supabase/                # DB schema, views, and triggers
â”œâ”€â”€ shiny_app/               # Web app source code
â”œâ”€â”€ looker/                  # Dashboard configs (example screenshots/queries)
â”œâ”€â”€ README.md
â””â”€â”€ .env.example             # Environment variable template
```
### What I Learned
Building robust automation for web scraping with session handling.

Using Supabase as a cloud data warehouse.

Writing efficient SQL for real-time views and triggers.

Combining open-source and SaaS BI tools for end-to-end reporting.

### âœ… How to Use
Clone this repo

Add your .env file with credentials (Playwright auth, Supabase keys).

Run the scraper script to pull fresh data.

Supabase will automatically update views & triggers.

Access your dashboards in Shiny and Looker!

### ğŸ¤ License & Notes
This project is for demonstration purposes only.
All data shown is fictional or test data.
*** No proprietary member information is shared.***
All APIs are secret and not hardcoded

### ğŸ‘‹ About Me
Iâ€™m a data analyst passionate about automating workflows and delivering clear insights.
Letâ€™s connect!
