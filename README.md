# ğŸ“Š Automated Attendance Pipeline & Dashboard


### ğŸ“Œ Overview
This project automates the extraction, transformation, and reporting of member attendance data from a PushPress Looker dashboard.
It demonstrates how to build a full-stack data pipeline, leveraging automation, cloud database engineering, and interactive dashboards to generate actionable business insights.

### ğŸš€ Key Features
- âœ… Automated scraping of an embedded dashboard (with secure login & filter selection)
  
- âœ… Dynamic query manipulation (e.g., increase export limits)
  
- âœ… Parsing and storing clean data in Supabase (PostgreSQL)
  
- âœ… SQL views & triggers to transform and manage data
  
- âœ… Interactive web app in Shiny for real-time monitoring
  
- âœ… Additional Looker dashboard to track new leads & kidsâ€™ attendance trends

### ğŸ”— Full Workflow
```mermaid
flowchart LR
  A["***Automated Scraper***(Python + Playwright)"]
  B["***Supabase***(PostgreSQL)"]
  C["SQL Views & Triggers"]
  D["Shiny Web App"]
  E["Looker Dashboard"]

  A --> B
  B --> C
  C --> D
  C --> E
  D <--> B
```
### How it works:
1. Authenticate â†’ filter â†’ export fresh data automatically
2. Clean and push data to Supabase
3. Use views to filter kids vs. adults & identify new members
4. Triggers keep summary tables updated
5. Serve insights via Shiny and Looker dashboards

### ğŸ—„ï¸ Data Pipeline Highlights
- Automation: Playwright (Python) handles automatic login, filter selection, dynamic CSV exports, URL manipulation and API calls to SupaBase.
- Cloud Storage: Supabase Postgres stores all check-ins, sessions, and member details.
- Data Modeling: SQL views separate kidsâ€™ attendance and identify new kids for promotions. 
- Business Logic: Triggers & functions automatically manage new lead and kids records.
- Reporting: Shiny dashboard for internal use, Looker for stakeholder reporting.

### ğŸ”’ Security & Best Practices
.env files used for API keys and credentials â€” never hardcoded.

### ğŸ› ï¸ Tech Stack
| Layer            | Tool/Framework            |
| ---------------- | ------------------------- |
| **Automation**   | Python, Playwright        |
| **Data Storage** | Supabase (PostgreSQL)     |
| **Processing**   | SQL (views, triggers)     |
| **Reporting**    | Shiny, Looker Studio      |
| **Deployment**   | GitHub Actions & Supabase |


### âœ¨ Impact
âœ… Improved data accuracy & consistency by automating manual CSV exports
âœ… Reduced admin effort for tracking kidsâ€™ promotions & new leads
âœ… Better business insights with self-serve dashboards & real-time updates

### ğŸ“‚ Repository Structure
```bash
â”œâ”€â”€ daily_update.py/         # Scraper scripts
â”œâ”€â”€ pushdata.py/             # Saving data to supabase
â”œâ”€â”€ update_kids_shiny.py/    # Web app source code
â”œâ”€â”€ main.py/                 # FastAPI
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt         # Packages
```
### What I Learned
Building robust automation for web scraping with session handling.

Using Supabase as a cloud data warehouse.

Writing efficient SQL for real-time views and triggers.

Combining open-source and SaaS BI tools for end-to-end reporting.

### âœ… How to Use
Clone this repo

Add your .env file with credentials (Playwright auth, Supabase keys).

Run the scraper script to pull fresh data.

Supabase will automatically update views & triggers.

Access your dashboards in Shiny and Looker!

### ğŸ¤ License & Notes
- This project is for demonstration purposes only.

- All data shown is fictional or test data.

- ***No proprietary member information is shared.***

- All APIs are secret and not hardcoded

### ğŸ‘‹ About Me
Iâ€™m a data analyst passionate about automating workflows and delivering clear insights. Strong problem solving skills.
Letâ€™s connect!
