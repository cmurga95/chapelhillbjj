name: Scrape and Push to Supabase

on:
  schedule:
    - cron: '0 4 * * *'  # Runs every day at 12:00 UTC (adjust as needed)
  workflow_dispatch:  # Allows manual run

jobs:
  scrape-and-upload:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: pip install -r requirements.txt
        
      - name: Install Playwright browsers
        run: playwright install
        
      - name: Run scraping script
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          USER: ${{ secrets.USER }}
          PASSWORD: ${{secrets.PASSWORD }}
          HOST: ${{secrets.HOST }}
          PORT: ${{secrets.PORT }}
          DBNAME: ${{secrets.DBNAME }}
          URL_PP: ${{ secrets.URL_PP }}
          EMAIL_PP: ${{ secrets.EMAIL_PP }}
          PASSWORD_PP: ${{ secrets.PASSWORD_PP }}
          run: |
            echo "EMAIL_PP is set: ${EMAIL_PP:+yes}"
            echo "PASSWORD_PP is set: ${PASSWORD_PP:+yes}"
            echo "URL_PP is set: ${URL_PP:+yes}"
        
        run: python pushdata.py
